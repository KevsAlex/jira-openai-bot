

import json

from langchain_openai import ChatOpenAI

from langchain.tools import format_tool_to_openai_function
import dotenv
import os



# For Message schemas,
from langchain.schema import HumanMessage, FunctionMessage

from customBot.JiraTicketTool import JiraTicketTool

dotenv.load_dotenv()
secret_key = os.getenv('OPENAI_API_KEY')

def jiraAgent(query):
    tools = [JiraTicketTool()]
    functions = [format_tool_to_openai_function(tool_name) for tool_name in tools]
    tool_map = {tool.name: tool for tool in tools}
    model_name = "gpt-3.5-turbo-16k"


    print('-------- FUNCTIONS ------------')
    print(functions)
    print('--------  ------------')

    print('-------- TOOLMAOP ------------')
    print(tool_map)
    print('--------  ------------')
    # Let's first create the chat model
    model = ChatOpenAI(
        model=model_name,
        temperature=0,
    )

    print('Query' + '\n ' + query)
    response_ai_message = model.predict_messages([HumanMessage(content=query)], functions=functions)
    _args = json.loads(response_ai_message.additional_kwargs['function_call'].get('arguments'))
    print('Json input Generated by IA'+'\n ')
    print(_args)

    tool_result = tools[0](_args)
    FunctionMessage(name="get_jira_tickets", content=str(tool_result))
    response_final = model.predict_messages(
        [
            HumanMessage(content=query),
            response_ai_message,
            FunctionMessage(name='get_jira_tickets', content=str(tool_result)),
        ],
        functions=functions
    )
    print(response_final)
    return response_final.content







